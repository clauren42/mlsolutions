{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Copyright (c) Microsoft Corporation. All rights reserved.\n\nLicensed under the MIT License."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Automated Machine Learning\n_**Orange Juice Sales Forecasting**_\n\n## Contents\n1. [Introduction](#Introduction)\n1. [Setup](#Setup)\n1. [Data](#Data)\n1. [Train](#Train)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Introduction\nIn this example, we use AutoML to find and tune a time-series forecasting model.\n\nMake sure you have executed the [configuration notebook](../../../configuration.ipynb) before running this notebook.\n\nIn this notebook, you will:\n1. Create an Experiment in an existing Workspace\n2. Instantiate an AutoMLConfig \n3. Find and train a forecasting model using local compute\n4. Evaluate the performance of the model\n\nThe examples in the follow code samples use the [University of Chicago's Dominick's Finer Foods dataset](https://research.chicagobooth.edu/kilts/marketing-databases/dominicks) to forecast orange juice sales. Dominick's was a grocery chain in the Chicago metropolitan area."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Setup\n\nAs part of the setup you have already created a <b>Workspace</b>. To run AutoML, you also need to create an <b>Experiment</b>. An Experiment is a named object in a Workspace which represents a predictive task, the output of which is a trained model and a set of evaluation metrics for the model. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import azureml.core\nimport pandas as pd\nimport numpy as np\nimport logging\nimport warnings\n# Squash warning messages for cleaner output in the notebook\nwarnings.showwarning = lambda *args, **kwargs: None\n\n\nfrom azureml.core.workspace import Workspace\nfrom azureml.core.experiment import Experiment\nfrom azureml.train.automl import AutoMLConfig\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ws = Workspace.from_config()\n\n# choose a name for the run history container in the workspace\nexperiment_name = 'automl-ojsalesforecasting'\n# project folder\nproject_folder = './sample_projects/automl-local-ojsalesforecasting'\n\nexperiment = Experiment(ws, experiment_name)\n\noutput = {}\noutput['SDK version'] = azureml.core.VERSION\noutput['Subscription ID'] = ws.subscription_id\noutput['Workspace'] = ws.name\noutput['Resource Group'] = ws.resource_group\noutput['Location'] = ws.location\noutput['Project Directory'] = project_folder\noutput['Run History Name'] = experiment_name\npd.set_option('display.max_colwidth', -1)\noutputDf = pd.DataFrame(data = output, index = [''])\noutputDf.T",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found the config file in: /home/nbuser/library/Module_2_Get Started with AzureML/config.json\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Location</th>\n      <td>eastus</td>\n    </tr>\n    <tr>\n      <th>Project Directory</th>\n      <td>./sample_projects/automl-local-ojsalesforecasting</td>\n    </tr>\n    <tr>\n      <th>Resource Group</th>\n      <td>aiconfnyc</td>\n    </tr>\n    <tr>\n      <th>Run History Name</th>\n      <td>automl-ojsalesforecasting</td>\n    </tr>\n    <tr>\n      <th>SDK version</th>\n      <td>1.0.17</td>\n    </tr>\n    <tr>\n      <th>Subscription ID</th>\n      <td>5d9f0467-1e93-45cb-9531-b2f8e715feb1</td>\n    </tr>\n    <tr>\n      <th>Workspace</th>\n      <td>aiconfnycws</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                                                    \nLocation           eastus                                           \nProject Directory  ./sample_projects/automl-local-ojsalesforecasting\nResource Group     aiconfnyc                                        \nRun History Name   automl-ojsalesforecasting                        \nSDK version        1.0.17                                           \nSubscription ID    5d9f0467-1e93-45cb-9531-b2f8e715feb1             \nWorkspace          aiconfnycws                                      "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Data\nYou are now ready to load the historical orange juice sales data. We will load the CSV file into a plain pandas DataFrame; the time column in the CSV is called _WeekStarting_, so it will be specially parsed into the datetime type."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "time_column_name = 'WeekStarting'\ndata = pd.read_csv(\"dominicks_OJ.csv\", parse_dates=[time_column_name])\ndata.head()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WeekStarting</th>\n      <th>Store</th>\n      <th>Brand</th>\n      <th>Quantity</th>\n      <th>logQuantity</th>\n      <th>Advert</th>\n      <th>Price</th>\n      <th>Age60</th>\n      <th>COLLEGE</th>\n      <th>INCOME</th>\n      <th>Hincome150</th>\n      <th>Large HH</th>\n      <th>Minorities</th>\n      <th>WorkingWoman</th>\n      <th>SSTRDIST</th>\n      <th>SSTRVOL</th>\n      <th>CPDIST5</th>\n      <th>CPWVOL5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1990-06-14</td>\n      <td>2</td>\n      <td>dominicks</td>\n      <td>10560</td>\n      <td>9.26</td>\n      <td>1</td>\n      <td>1.59</td>\n      <td>0.23</td>\n      <td>0.25</td>\n      <td>10.55</td>\n      <td>0.46</td>\n      <td>0.10</td>\n      <td>0.11</td>\n      <td>0.30</td>\n      <td>2.11</td>\n      <td>1.14</td>\n      <td>1.93</td>\n      <td>0.38</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1990-06-14</td>\n      <td>2</td>\n      <td>minute.maid</td>\n      <td>4480</td>\n      <td>8.41</td>\n      <td>0</td>\n      <td>3.17</td>\n      <td>0.23</td>\n      <td>0.25</td>\n      <td>10.55</td>\n      <td>0.46</td>\n      <td>0.10</td>\n      <td>0.11</td>\n      <td>0.30</td>\n      <td>2.11</td>\n      <td>1.14</td>\n      <td>1.93</td>\n      <td>0.38</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1990-06-14</td>\n      <td>2</td>\n      <td>tropicana</td>\n      <td>8256</td>\n      <td>9.02</td>\n      <td>0</td>\n      <td>3.87</td>\n      <td>0.23</td>\n      <td>0.25</td>\n      <td>10.55</td>\n      <td>0.46</td>\n      <td>0.10</td>\n      <td>0.11</td>\n      <td>0.30</td>\n      <td>2.11</td>\n      <td>1.14</td>\n      <td>1.93</td>\n      <td>0.38</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1990-06-14</td>\n      <td>5</td>\n      <td>dominicks</td>\n      <td>1792</td>\n      <td>7.49</td>\n      <td>1</td>\n      <td>1.59</td>\n      <td>0.12</td>\n      <td>0.32</td>\n      <td>10.92</td>\n      <td>0.54</td>\n      <td>0.10</td>\n      <td>0.05</td>\n      <td>0.41</td>\n      <td>3.80</td>\n      <td>0.68</td>\n      <td>1.60</td>\n      <td>0.74</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1990-06-14</td>\n      <td>5</td>\n      <td>minute.maid</td>\n      <td>4224</td>\n      <td>8.35</td>\n      <td>0</td>\n      <td>2.99</td>\n      <td>0.12</td>\n      <td>0.32</td>\n      <td>10.92</td>\n      <td>0.54</td>\n      <td>0.10</td>\n      <td>0.05</td>\n      <td>0.41</td>\n      <td>3.80</td>\n      <td>0.68</td>\n      <td>1.60</td>\n      <td>0.74</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "  WeekStarting  Store        Brand  Quantity  logQuantity  Advert  Price  \\\n0 1990-06-14    2      dominicks    10560    9.26          1      1.59     \n1 1990-06-14    2      minute.maid  4480     8.41          0      3.17     \n2 1990-06-14    2      tropicana    8256     9.02          0      3.87     \n3 1990-06-14    5      dominicks    1792     7.49          1      1.59     \n4 1990-06-14    5      minute.maid  4224     8.35          0      2.99     \n\n   Age60  COLLEGE  INCOME  Hincome150  Large HH  Minorities  WorkingWoman  \\\n0 0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n1 0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n2 0.23   0.25     10.55   0.46        0.10      0.11        0.30            \n3 0.12   0.32     10.92   0.54        0.10      0.05        0.41            \n4 0.12   0.32     10.92   0.54        0.10      0.05        0.41            \n\n   SSTRDIST  SSTRVOL  CPDIST5  CPWVOL5  \n0 2.11      1.14     1.93     0.38      \n1 2.11      1.14     1.93     0.38      \n2 2.11      1.14     1.93     0.38      \n3 3.80      0.68     1.60     0.74      \n4 3.80      0.68     1.60     0.74      "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Each row in the DataFrame holds a quantity of weekly sales for an OJ brand at a single store. The data also includes the sales price, a flag indicating if the OJ brand was advertised in the store that week, and some customer demographic information based on the store location. For historical reasons, the data also include the logarithm of the sales quantity. The Dominick's grocery data is commonly used to illustrate econometric modeling techniques where logarithms of quantities are generally preferred.    \n\nThe task is now to build a time-series model for the _Quantity_ column. It is important to note that this dataset is comprised of many individual time-series - one for each unique combination of _Store_ and _Brand_. To distinguish the individual time-series, we thus define the **grain** - the columns whose values determine the boundaries between time-series: "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "grain_column_names = ['Store', 'Brand']\nnseries = data.groupby(grain_column_names).ngroups\nprint('Data contains {0} individual time-series.'.format(nseries))",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Data contains 249 individual time-series.\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Data Splitting\nFor the purposes of demonstration and later forecast evaluation, we now split the data into a training and a testing set. The test set will contain the final 20 weeks of observed sales for each time-series."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ntest_periods = 20\n\ndef split_last_n_by_grain(df, n):\n    \"\"\"\n    Group df by grain and split on last n rows for each group\n    \"\"\"\n    df_grouped = (df.sort_values(time_column_name) # Sort by ascending time\n                  .groupby(grain_column_names, group_keys=False))\n    df_head = df_grouped.apply(lambda dfg: dfg.iloc[:-n])\n    df_tail = df_grouped.apply(lambda dfg: dfg.iloc[-n:])\n    return df_head, df_tail\n\nX_train, X_test = split_last_n_by_grain(data, ntest_periods)",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Modeling\n\nFor forecasting tasks, AutoML uses pre-processing and estimation steps that are specific to time-series. AutoML will undertake the following pre-processing steps:\n* Detect time-series sample frequency (e.g. hourly, daily, weekly) and create new records for absent time points to make the series regular. A regular time series has a well-defined frequency and has a value at every sample point in a contiguous time span \n* Impute missing values in the target (via forward-fill) and feature columns (using median column values) \n* Create grain-based features to enable fixed effects across different series\n* Create time-based features to assist in learning seasonal patterns\n* Encode categorical variables to numeric quantities\n\nAutoML will currently train a single, regression-type model across **all** time-series in a given training set. This allows the model to generalize across related series.\n\nYou are almost ready to start an AutoML training job. We will first need to create a validation set from the existing training set (i.e. for hyper-parameter tuning): "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "nvalidation_periods = 20\nX_train, X_validate = split_last_n_by_grain(X_train, nvalidation_periods)",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We also need to separate the target column from the rest of the DataFrame: "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "target_column_name = 'Quantity'\ny_train = X_train.pop(target_column_name).values\ny_validate = X_validate.pop(target_column_name).values ",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Train\n\nThe AutoMLConfig object defines the settings and data for an AutoML training job. Here, we set necessary inputs like the task type, the number of AutoML iterations to try, and the training and validation data. \n\nFor forecasting tasks, there are some additional parameters that can be set: the name of the column holding the date/time and the grain column names. A time column is required for forecasting, while the grain is optional. If a grain is not given, the forecaster assumes that the whole dataset is a single time-series. We also pass a list of columns to drop prior to modeling. The _logQuantity_ column is completely correlated with the target quantity, so it must be removed to prevent a target leak. \n\n|Property|Description|\n|-|-|\n|**task**|forecasting|\n|**primary_metric**|This is the metric that you want to optimize.<br> Forecasting supports the following primary metrics <br><i>spearman_correlation</i><br><i>normalized_root_mean_squared_error</i><br><i>r2_score</i><br><i>normalized_mean_absolute_error</i>\n|**iterations**|Number of iterations. In each iteration, Auto ML trains a specific pipeline on the given data|\n|**X**|Training matrix of features, shape = [n_training_samples, n_features]|\n|**y**|Target values, shape = [n_training_samples, ]|\n|**X_valid**|Validation matrix of features, shape = [n_validation_samples, n_features]|\n|**y_valid**|Target values for validation, shape = [n_validation_samples, ]\n|**enable_ensembling**|Allow AutoML to create ensembles of the best performing models\n|**debug_log**|Log file path for writing debugging information\n|**path**|Relative path to the project folder.  AutoML stores configuration files for the experiment under this folder. You can specify a new empty folder. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "automl_settings = {\n    'time_column_name': time_column_name,\n    'grain_column_names': grain_column_names,\n    'drop_column_names': ['logQuantity']\n}\n\nautoml_config = AutoMLConfig(task='forecasting',\n                             debug_log='automl_oj_sales_errors.log',\n                             primary_metric='normalized_root_mean_squared_error',\n                             iterations=10,\n                             X=X_train,\n                             y=y_train,\n                             X_valid=X_validate,\n                             y_valid=y_validate,\n                             enable_ensembling=False,\n                             path=project_folder,\n                             verbosity=logging.INFO,\n                            **automl_settings)",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can now submit a new training run. For local runs, the execution is synchronous. Depending on the data and number of iterations this operation may take several minutes.\nInformation from each iteration will be printed to the console."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "local_run = experiment.submit(automl_config, show_output=True)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Running on local machine\nParent Run ID: AutoML_1c5c59c3-cad5-440a-92ba-adbba5d6b846\n********************************************************************************************************************\nITERATION: The iteration being evaluated.\nPIPELINE: A summary description of the pipeline being evaluated.\nSAMPLING %: Percent of the training data to sample.\nDURATION: Time taken for the current iteration.\nMETRIC: The result of computing score on the fitted pipeline.\nBEST: The best observed score thus far.\n********************************************************************************************************************\n\n ITERATION   PIPELINE                                       SAMPLING %  DURATION      METRIC      BEST\n         0   StandardScalerWrapper ElasticNet               100.0000    0:00:34       0.0305    0.0305\n         1   StandardScalerWrapper ElasticNet               100.0000    0:00:25       0.0300    0.0300\n         2   StandardScalerWrapper ElasticNet               100.0000    0:00:20       0.0303    0.0300\n         3   StandardScalerWrapper ElasticNet               100.0000    0:00:27       0.0298    0.0298\n         4   StandardScalerWrapper ElasticNet               100.0000    0:00:20       0.0314    0.0298\n         5   StandardScalerWrapper ElasticNet               100.0000    0:00:24       0.0299    0.0298\n         6   RobustScaler ElasticNet                        100.0000    0:00:20       0.0305    0.0298\n         7   StandardScalerWrapper LightGBM                 100.0000    0:00:11       0.0282    0.0282\n         8   RobustScaler DecisionTree                      100.0000    0:00:11       0.0279    0.0279\n         9   StandardScalerWrapper LightGBM                 100.0000    0:00:12       0.0273    0.0273\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "local_run",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl-ojsalesforecasting</td><td>AutoML_1c5c59c3-cad5-440a-92ba-adbba5d6b846</td><td>automl</td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/5d9f0467-1e93-45cb-9531-b2f8e715feb1/resourceGroups/aiconfnyc/providers/Microsoft.MachineLearningServices/workspaces/aiconfnycws/experiments/automl-ojsalesforecasting/runs/AutoML_1c5c59c3-cad5-440a-92ba-adbba5d6b846\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>",
            "text/plain": "Run(Experiment: automl-ojsalesforecasting,\nId: AutoML_1c5c59c3-cad5-440a-92ba-adbba5d6b846,\nType: automl,\nStatus: Completed)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Retrieve the Best Model\nEach run within an Experiment stores serialized (i.e. pickled) pipelines from the AutoML iterations. We can now retrieve the pipeline with the best performance on the validation dataset:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "best_run, fitted_pipeline = local_run.get_output()\nfitted_pipeline.steps",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "[('timeseriestransformer', TimeSeriesTransformer(logger=None)),\n ('standardscalerwrapper',\n  <automl.client.core.common.model_wrappers.StandardScalerWrapper at 0x7fb1a48aeac8>),\n ('lightgbmregressor',\n  <automl.client.core.common.model_wrappers.LightGBMRegressor at 0x7fb1a48ae6a0>)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Make Predictions from the Best Fitted Model\nNow that we have retrieved the best pipeline/model, it can be used to make predictions on test data. First, we remove the target values from the test set:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_test = X_test.pop(target_column_name).values",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "X_test.head()",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>WeekStarting</th>\n      <th>Store</th>\n      <th>Brand</th>\n      <th>logQuantity</th>\n      <th>Advert</th>\n      <th>Price</th>\n      <th>Age60</th>\n      <th>COLLEGE</th>\n      <th>INCOME</th>\n      <th>Hincome150</th>\n      <th>Large HH</th>\n      <th>Minorities</th>\n      <th>WorkingWoman</th>\n      <th>SSTRDIST</th>\n      <th>SSTRVOL</th>\n      <th>CPDIST5</th>\n      <th>CPWVOL5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24192</th>\n      <td>1992-05-21</td>\n      <td>2</td>\n      <td>dominicks</td>\n      <td>9.18</td>\n      <td>0</td>\n      <td>1.69</td>\n      <td>0.23</td>\n      <td>0.25</td>\n      <td>10.55</td>\n      <td>0.46</td>\n      <td>0.10</td>\n      <td>0.11</td>\n      <td>0.30</td>\n      <td>2.11</td>\n      <td>1.14</td>\n      <td>1.93</td>\n      <td>0.38</td>\n    </tr>\n    <tr>\n      <th>24441</th>\n      <td>1992-05-28</td>\n      <td>2</td>\n      <td>dominicks</td>\n      <td>10.73</td>\n      <td>0</td>\n      <td>1.69</td>\n      <td>0.23</td>\n      <td>0.25</td>\n      <td>10.55</td>\n      <td>0.46</td>\n      <td>0.10</td>\n      <td>0.11</td>\n      <td>0.30</td>\n      <td>2.11</td>\n      <td>1.14</td>\n      <td>1.93</td>\n      <td>0.38</td>\n    </tr>\n    <tr>\n      <th>24675</th>\n      <td>1992-06-04</td>\n      <td>2</td>\n      <td>dominicks</td>\n      <td>9.95</td>\n      <td>0</td>\n      <td>1.74</td>\n      <td>0.23</td>\n      <td>0.25</td>\n      <td>10.55</td>\n      <td>0.46</td>\n      <td>0.10</td>\n      <td>0.11</td>\n      <td>0.30</td>\n      <td>2.11</td>\n      <td>1.14</td>\n      <td>1.93</td>\n      <td>0.38</td>\n    </tr>\n    <tr>\n      <th>24909</th>\n      <td>1992-06-11</td>\n      <td>2</td>\n      <td>dominicks</td>\n      <td>8.79</td>\n      <td>0</td>\n      <td>2.09</td>\n      <td>0.23</td>\n      <td>0.25</td>\n      <td>10.55</td>\n      <td>0.46</td>\n      <td>0.10</td>\n      <td>0.11</td>\n      <td>0.30</td>\n      <td>2.11</td>\n      <td>1.14</td>\n      <td>1.93</td>\n      <td>0.38</td>\n    </tr>\n    <tr>\n      <th>25152</th>\n      <td>1992-06-18</td>\n      <td>2</td>\n      <td>dominicks</td>\n      <td>8.52</td>\n      <td>0</td>\n      <td>2.05</td>\n      <td>0.23</td>\n      <td>0.25</td>\n      <td>10.55</td>\n      <td>0.46</td>\n      <td>0.10</td>\n      <td>0.11</td>\n      <td>0.30</td>\n      <td>2.11</td>\n      <td>1.14</td>\n      <td>1.93</td>\n      <td>0.38</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "      WeekStarting  Store      Brand  logQuantity  Advert  Price  Age60  \\\n24192 1992-05-21    2      dominicks 9.18          0      1.69   0.23     \n24441 1992-05-28    2      dominicks 10.73         0      1.69   0.23     \n24675 1992-06-04    2      dominicks 9.95          0      1.74   0.23     \n24909 1992-06-11    2      dominicks 8.79          0      2.09   0.23     \n25152 1992-06-18    2      dominicks 8.52          0      2.05   0.23     \n\n       COLLEGE  INCOME  Hincome150  Large HH  Minorities  WorkingWoman  \\\n24192 0.25     10.55   0.46        0.10      0.11        0.30            \n24441 0.25     10.55   0.46        0.10      0.11        0.30            \n24675 0.25     10.55   0.46        0.10      0.11        0.30            \n24909 0.25     10.55   0.46        0.10      0.11        0.30            \n25152 0.25     10.55   0.46        0.10      0.11        0.30            \n\n       SSTRDIST  SSTRVOL  CPDIST5  CPWVOL5  \n24192 2.11      1.14     1.93     0.38      \n24441 2.11      1.14     1.93     0.38      \n24675 2.11      1.14     1.93     0.38      \n24909 2.11      1.14     1.93     0.38      \n25152 2.11      1.14     1.93     0.38      "
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To produce predictions on the test set, we need to know the feature values at all dates in the test set. This requirement is somewhat reasonable for the OJ sales data since the features mainly consist of price, which is usually set in advance, and customer demographics which are approximately constant for each store over the 20 week forecast horizon in the testing data. \n\nThe target predictions can be retrieved by calling the `predict` method on the best model:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_pred = fitted_pipeline.predict(X_test)",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Calculate evaluation metrics for the prediction\nTo evaluate the accuracy of the forecast, we'll compare against the actual sales quantities for some select metrics, included the mean absolute percentage error (MAPE)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def MAPE(actual, pred):\n    \"\"\"\n    Calculate mean absolute percentage error.\n    Remove NA and values where actual is close to zero\n    \"\"\"\n    not_na = ~(np.isnan(actual) | np.isnan(pred))\n    not_zero = ~np.isclose(actual, 0.0)\n    actual_safe = actual[not_na & not_zero]\n    pred_safe = pred[not_na & not_zero]\n    APE = 100*np.abs((actual_safe - pred_safe)/actual_safe)\n    return np.mean(APE)\n\nprint(\"[Test Data] \\nRoot Mean squared error: %.2f\" % np.sqrt(mean_squared_error(y_test, y_pred)))\nprint('mean_absolute_error score: %.2f' % mean_absolute_error(y_test, y_pred))\nprint('MAPE: %.2f' % MAPE(y_test, y_pred))",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[Test Data] \nRoot Mean squared error: 16158.98\nmean_absolute_error score: 8588.16\nMAPE: 73.83\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "authors": [
      {
        "name": "erwright"
      }
    ],
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}