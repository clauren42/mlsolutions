{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Feature Engineering for Time Series\n",
    "\n",
    "## Minimum Daily Temperatures Dataset\n",
    "\n",
    "In this notebook, we learn how to do Feature Engineering for Time Series with the Minimum Daily Temperatures dataset. This dataset describes the minimum daily temperatures over 10 years (1981-1990) in the city Melbourne, Australia. The units are in degrees Celsius and there are 3650 observations. \n",
    "\n",
    "The source of the data is credited as the Australian Bureau of Meteorology. Download the dataset and place it in your current working directory with the name daily-minimum-temperatures.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/daily-minimum-temperatures.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month  day  temperature\n",
      "0      1    1         20.7\n",
      "1      1    2         17.9\n",
      "2      1    3         18.8\n",
      "3      1    4         14.6\n",
      "4      1    5         15.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Date\n",
       "1981-01-01    20.7\n",
       "1981-01-02    17.9\n",
       "1981-01-03    18.8\n",
       "1981-01-04    14.6\n",
       "1981-01-05    15.8\n",
       "1981-01-06    15.8\n",
       "1981-01-07    15.8\n",
       "1981-01-08    17.4\n",
       "1981-01-09    21.8\n",
       "1981-01-10    20.0\n",
       "1981-01-11    16.2\n",
       "1981-01-12    13.3\n",
       "1981-01-13    16.7\n",
       "1981-01-14    21.5\n",
       "1981-01-15    25.0\n",
       "1981-01-16    20.7\n",
       "1981-01-17    20.6\n",
       "1981-01-18    24.8\n",
       "1981-01-19    17.7\n",
       "1981-01-20    15.5\n",
       "1981-01-21    18.2\n",
       "1981-01-22    12.1\n",
       "1981-01-23    14.4\n",
       "1981-01-24    16.0\n",
       "1981-01-25    16.5\n",
       "1981-01-26    18.7\n",
       "1981-01-27    19.4\n",
       "1981-01-28    17.2\n",
       "1981-01-29    15.5\n",
       "1981-01-30    15.1\n",
       "              ... \n",
       "1990-12-02    13.2\n",
       "1990-12-03    16.2\n",
       "1990-12-04    17.3\n",
       "1990-12-05    20.5\n",
       "1990-12-06    20.2\n",
       "1990-12-07    19.4\n",
       "1990-12-08    15.5\n",
       "1990-12-09    14.1\n",
       "1990-12-10    11.0\n",
       "1990-12-11    11.1\n",
       "1990-12-12    14.0\n",
       "1990-12-13    11.4\n",
       "1990-12-14    12.5\n",
       "1990-12-15    13.4\n",
       "1990-12-16    13.6\n",
       "1990-12-17    13.9\n",
       "1990-12-18    17.2\n",
       "1990-12-19    14.7\n",
       "1990-12-20    15.4\n",
       "1990-12-21    13.1\n",
       "1990-12-22    13.2\n",
       "1990-12-23    13.9\n",
       "1990-12-24    10.0\n",
       "1990-12-25    12.9\n",
       "1990-12-26    14.6\n",
       "1990-12-27    14.0\n",
       "1990-12-28    13.6\n",
       "1990-12-29    13.5\n",
       "1990-12-30    15.7\n",
       "1990-12-31    13.0\n",
       "Name: Temp, Length: 3650, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create date time features of a dataset\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "series = read_csv(data_path, header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "dataframe = DataFrame()\n",
    "dataframe['month'] = [series.index[i].month for i in range(len(series))]\n",
    "dataframe['day'] = [series.index[i].day for i in range(len(series))]\n",
    "dataframe['temperature'] = [series[i] for i in range(len(series))]\n",
    "print(dataframe.head(5))\n",
    "\n",
    "series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using just the month and day information alone to predict temperature is not sophisticated and will likely result in a poor model. Nevertheless, this information coupled with additional engineered features may ultimately result in a better model. You may enumerate all the properties of a time-stamp and consider what might be useful for your problem, such as: \n",
    "- Minutes elapsed for the day.\n",
    "- Hour of day.\n",
    "- Business hours or not.\n",
    "- Weekend or not.\n",
    "- Season of the year.\n",
    "- Business quarter of the year.\n",
    "- Daylight savings or not.\n",
    "- Public holiday or not.\n",
    "- Leap year or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      t   t+1\n",
      "0   NaN  20.7\n",
      "1  20.7  17.9\n",
      "2  17.9  18.8\n",
      "3  18.8  14.6\n",
      "4  14.6  15.8\n"
     ]
    }
   ],
   "source": [
    "# create a lag feature\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "series = read_csv(data_path, header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "temps = DataFrame(series.values)\n",
    "dataframe = concat([temps.shift(1), temps], axis=1)\n",
    "dataframe.columns = ['t', 't+1']\n",
    "print(dataframe.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    t-2   t-1     t   t+1\n",
      "0   NaN   NaN   NaN  20.7\n",
      "1   NaN   NaN  20.7  17.9\n",
      "2   NaN  20.7  17.9  18.8\n",
      "3  20.7  17.9  18.8  14.6\n",
      "4  17.9  18.8  14.6  15.8\n"
     ]
    }
   ],
   "source": [
    "# create lag features\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "series = read_csv(data_path, header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "temps = DataFrame(series.values)\n",
    "dataframe = concat([temps.shift(3), temps.shift(2), temps.shift(1), temps], axis=1)\n",
    "dataframe.columns = ['t-2', 't-1', 't', 't+1']\n",
    "print(dataframe.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean(t-1,t)   t+1\n",
      "0          NaN  20.7\n",
      "1          NaN  17.9\n",
      "2        19.30  18.8\n",
      "3        18.35  14.6\n",
      "4        16.70  15.8\n"
     ]
    }
   ],
   "source": [
    "# create a rolling mean feature\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "series = read_csv(data_path, header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "temps = DataFrame(series.values)\n",
    "shifted = temps.shift(1)\n",
    "window = shifted.rolling(window=2)\n",
    "means = window.mean()\n",
    "dataframe = concat([means, temps], axis=1)\n",
    "dataframe.columns = ['mean(t-1,t)', 't+1']\n",
    "print(dataframe.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    min       mean   max   t+1\n",
      "0   NaN        NaN   NaN  20.7\n",
      "1   NaN        NaN   NaN  17.9\n",
      "2   NaN        NaN   NaN  18.8\n",
      "3   NaN        NaN   NaN  14.6\n",
      "4  17.9  19.133333  20.7  15.8\n"
     ]
    }
   ],
   "source": [
    "# create rolling statistics features\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "series = read_csv(data_path, header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "temps = DataFrame(series.values)\n",
    "width = 3\n",
    "shifted = temps.shift(width - 1)\n",
    "window = shifted.rolling(window=width)\n",
    "dataframe = concat([window.min(), window.mean(), window.max(), temps], axis=1)\n",
    "dataframe.columns = ['min', 'mean', 'max', 't+1']\n",
    "print(dataframe.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    min       mean   max   t+1\n",
      "0  20.7  20.700000  20.7  17.9\n",
      "1  17.9  19.300000  20.7  18.8\n",
      "2  17.9  19.133333  20.7  14.6\n",
      "3  14.6  18.000000  20.7  15.8\n",
      "4  14.6  17.560000  20.7  15.8\n"
     ]
    }
   ],
   "source": [
    "# create expanding window features\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "series = read_csv(data_path, header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "temps = DataFrame(series.values)\n",
    "window = temps.expanding()\n",
    "dataframe = concat([window.min(), window.mean(), window.max(), temps.shift(-1)], axis=1)\n",
    "dataframe.columns = ['min', 'mean', 'max', 't+1']\n",
    "print(dataframe.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "The website Data Market provides access to a large number of time series datasets. Specically, the Time Series Data Library (https://datamarket.com/data/list/?q=provider:tsdl) created by Rob Hyndman, Professor of Statistics at Monash University, Australia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (azureml)",
   "language": "python",
   "name": "azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
