{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Moving Average Models for Forecasting\n\nThe residual errors from forecasts on a time series provide another source of information that we can model. Residual errors themselves form a time series that can have temporal structure. A simple autoregression model of this structure can be used to predict the forecast error, which\nin turn can be used to correct forecasts. In this notebook, you will discover how to model a residual error time series and use it to correct predictions with Python."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_path = './data/daily-total-female-births.csv'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# autoregressive model of residual errors\nfrom pandas import read_csv\nfrom pandas import DataFrame\nfrom pandas import concat\nfrom statsmodels.tsa.ar_model import AR\nseries = read_csv(data_path, header=0, index_col=0, parse_dates=True, squeeze=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# create lagged dataset\nvalues = DataFrame(series.values)\ndataframe = concat([values.shift(1), values], axis=1)\ndataframe.columns = ['t', 't+1']\n\n# split into train and test sets\nX = dataframe.values\ntrain_size = int(len(X) * 0.66)\ntrain, test = X[1:train_size], X[train_size:]\ntrain_X, train_y = train[:,0], train[:,1]\ntest_X, test_y = test[:,0], test[:,1]\n\n# persistence model on training set\ntrain_pred = [x for x in train_X]\n\n# calculate residuals\ntrain_resid = [train_y[i]-train_pred[i] for i in range(len(train_pred))]\n\n# model the training set residuals\nmodel = AR(train_resid)\nmodel_fit = model.fit()\nwindow = model_fit.k_ar\ncoef = model_fit.params\nprint('Lag=%d, Coef=%s' % (window, coef))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# forecast residual forecast error\nfrom pandas import read_csv\nfrom pandas import DataFrame\nfrom pandas import concat\nfrom statsmodels.tsa.ar_model import AR\nfrom matplotlib import pyplot\nseries = read_csv(data_path, header=0, index_col=0, parse_dates=True, squeeze=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# create lagged dataset\nvalues = DataFrame(series.values)\ndataframe = concat([values.shift(1), values], axis=1)\ndataframe.columns = ['t', 't+1']\n\n# split into train and test sets\nX = dataframe.values\ntrain_size = int(len(X) * 0.66)\ntrain, test = X[1:train_size], X[train_size:]\ntrain_X, train_y = train[:,0], train[:,1]\ntest_X, test_y = test[:,0], test[:,1]\n\n# persistence model on training set\ntrain_pred = [x for x in train_X]\n\n# calculate residuals\ntrain_resid = [train_y[i]-train_pred[i] for i in range(len(train_pred))]\n\n# model the training set residuals\nmodel = AR(train_resid)\nmodel_fit = model.fit()\nwindow = model_fit.k_ar\ncoef = model_fit.params\n\n# walk forward over time steps in test\nhistory = train_resid[len(train_resid)-window:]\nhistory = [history[i] for i in range(len(history))]\npredictions = list()\nexpected_error = list()\nfor t in range(len(test_y)):\n    # persistence\n    yhat = test_X[t]\n    error = test_y[t] - yhat\n    expected_error.append(error)\n    # predict error\n    length = len(history)\n    lag = [history[i] for i in range(length-window,length)]\n    pred_error = coef[0]\n    \n    for d in range(window):\n        pred_error += coef[d+1] * lag[window-d-1]\n        predictions.append(pred_error)\n        history.append(error)\n        print('predicted error=%f, expected error=%f' % (pred_error, error))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# plot predicted error\npyplot.plot(expected_error, label='Expected error')\npyplot.plot(predictions, color='red', label='Prediction')\npyplot.legend()\npyplot.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Correct Predictions with a Model of Residuals"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# correct the prediction\nyhat = yhat + pred_error",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# correct forecasts with a model of forecast residual errors\nfrom pandas import read_csv\nfrom pandas import DataFrame\nfrom pandas import concat\nfrom statsmodels.tsa.ar_model import AR\nfrom matplotlib import pyplot\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\n\n# load data\nseries = read_csv(data_path, header=0, index_col=0, parse_dates=True, squeeze=True)\n\n# create lagged dataset\nvalues = DataFrame(series.values)\ndataframe = concat([values.shift(1), values], axis=1)\ndataframe.columns = ['t', 't+1']\n\n# split into train and test sets\nX = dataframe.values\ntrain_size = int(len(X) * 0.66)\ntrain, test = X[1:train_size], X[train_size:]\ntrain_X, train_y = train[:,0], train[:,1]\ntest_X, test_y = test[:,0], test[:,1]\n\n# persistence model on training set\ntrain_pred = [x for x in train_X]\n\n# calculate residuals\ntrain_resid = [train_y[i]-train_pred[i] for i in range(len(train_pred))]\n\n# model the training set residuals\nmodel = AR(train_resid)\nmodel_fit = model.fit()\nwindow = model_fit.k_ar\ncoef = model_fit.params\n\n# walk forward over time steps in test\nhistory = train_resid[len(train_resid)-window:]\nhistory = [history[i] for i in range(len(history))]\npredictions = list()\nfor t in range(len(test_y)):\n    # persistence\n    yhat = test_X[t]\n    error = test_y[t] - yhat\n    # predict error\n    length = len(history)\n    lag = [history[i] for i in range(length-window,length)]\n    pred_error = coef[0]\n    for d in range(window):\n        pred_error += coef[d+1] * lag[window-d-1]\n    # correct the prediction\n    yhat = yhat + pred_error\n    predictions.append(yhat)\n    history.append(error)\n    print('predicted=%f, expected=%f' % (yhat, test_y[t]))\n    \n# error\nrmse = sqrt(mean_squared_error(test_y, predictions))\nprint('Test RMSE: %.3f' % rmse)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# plot predicted error\npyplot.plot(test_y, label='Test y')\npyplot.plot(predictions, color='red', label='Prediction')\npyplot.legend()\npyplot.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "### References:\nThe website Data Market provides access to a large number of time series datasets. Specically, the Time Series Data Library (https://datamarket.com/data/list/?q=provider:tsdl) created by Rob Hyndman, Professor of Statistics at Monash University, Australia."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}